{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.network import Sequential\n",
    "import random\n",
    "\n",
    "from gym.vector import SyncVectorEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Normal\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_timesteps = 3000\n",
    "n_epochs = 10\n",
    "learning_rate = 0.0003\n",
    "gamma = 0.99\n",
    "eps_clip = 0.2\n",
    "K_epochs = 4\n",
    "action_std = 0.5\n",
    "batch_size = 64\n",
    "update_timestep = 2000\n",
    "\n",
    "beta = 0.0\n",
    "\n",
    "BEHAVIOR_DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(done, rewards, values, next_values, gamma=0.99, lambda_=0.95):\n",
    "    assert len(values) == len(next_values) == len(rewards) == len(done)\n",
    "\n",
    "    advantages = torch.zeros(done.shape[0], dtype=torch.float32)\n",
    "    returns = torch.zeros(done.shape[0], dtype=torch.float32)\n",
    "    last_advantage = 0\n",
    "    last_return = 0\n",
    "\n",
    "    for t in reversed(range(done.shape[0])):\n",
    "        mask = 1.0 - done[t]\n",
    "        last_value = next_values[t] * mask\n",
    "        last_advantage = last_advantage * mask\n",
    "        last_return = last_return * mask\n",
    "\n",
    "        delta = rewards[t] + gamma * last_value - values[t]\n",
    "        last_advantage = delta + gamma * lambda_ * last_advantage\n",
    "        last_return = rewards[t] + gamma * last_return\n",
    "\n",
    "        advantages[t] = last_advantage\n",
    "        returns[t] = last_return\n",
    "\n",
    "    return advantages, returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionedActorCriticContinuous(nn.Module):\n",
    "    def __init__(self, descriptor_dim, state_dim, action_dim, actor_hidden_layers, critic_hidden_layers, action_std):\n",
    "        super(ConditionedActorCriticContinuous, self).__init__()\n",
    "        \n",
    "        # Define actor network\n",
    "        actor_layers = []\n",
    "        input_dim = state_dim\n",
    "        for hidden_dim in actor_hidden_layers:\n",
    "            actor_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            actor_layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "        actor_layers.append(nn.Linear(input_dim, action_dim))\n",
    "        # actor_layers.append(nn.Tanh())\n",
    "        self.actor = nn.Sequential(*actor_layers)\n",
    "        \n",
    "        # Define critic network\n",
    "        critic_layers = []\n",
    "        input_dim = state_dim\n",
    "        for hidden_dim in critic_hidden_layers:\n",
    "            critic_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            critic_layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "        critic_layers.append(nn.Linear(input_dim, 1))\n",
    "        self.critic = nn.Sequential(*critic_layers)\n",
    "        \n",
    "        self.action_var = nn.Parameter(torch.full((action_dim,), action_std**2, requires_grad=True))\n",
    "\n",
    "\n",
    "    def forward(self, x, action=None):\n",
    "        # print(f\"{alpha.shape=}\")\n",
    "\n",
    "        action_mean = self.actor(x)\n",
    "        cov_matrix = torch.exp(self.action_var)\n",
    "        dist = Normal(loc=action_mean, scale=cov_matrix)\n",
    "        \n",
    "        if action is None:\n",
    "            action = dist.sample()\n",
    "            \n",
    "        log_p = dist.log_prob(action).sum(dim=-1)\n",
    "        \n",
    "        value = self.critic(x)\n",
    "                \n",
    "        return action, action_mean, log_p, value, dist.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(info):\n",
    "    d1 = np.mean([d1 for (d1, d2) in info])\n",
    "    d2 = np.mean([d2 for (d1, d2) in info])\n",
    "    return d1, d2\n",
    "    # return np.mean(info['bfoot_touch_ground']), np.mean(info['ffoot_touch_ground'])\n",
    "    \n",
    "    \n",
    "def get_descriptors_from_trajectories(data):\n",
    "    \n",
    "    num_envs = data['info'].shape[0]\n",
    "    \n",
    "    descriptors = []\n",
    "    for n in range(num_envs):\n",
    "        env_n_descriptors = []\n",
    "        trajectory_info = []\n",
    "        for i in range(len(data['info'][n])):\n",
    "            # print(i)\n",
    "            trajectory_info.append(data['info'][n][i])\n",
    "            \n",
    "            if data['done'][n][i] == True:\n",
    "                d1, d2 = get_descriptor(trajectory_info)\n",
    "                # d1, d2 = round(d1*BEHAVIOR_DIM), round(d2*BEHAVIOR_DIM)\n",
    "                descriptors.append((d1, d2))\n",
    "        \n",
    "        # descriptors.append(env_n_descriptors)\n",
    "        \n",
    "    return descriptors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def descriptors_to_vectors(descriptors):\n",
    "    vectors = []\n",
    "    for (d1, d2) in descriptors:\n",
    "        vector = [0]*(BEHAVIOR_DIM**2)\n",
    "        vector[d1*BEHAVIOR_DIM+d2] = 1\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "def descriptors_to_id(descriptors):\n",
    "    ids = []\n",
    "    for (d1, d2) in descriptors:\n",
    "        ids.append(d1*BEHAVIOR_DIM+d2)\n",
    "    return ids\n",
    "\n",
    "def descriptors_vec2coord(descriptors):\n",
    "    d_id = descriptors.argmax(axis=1)\n",
    "    d1, d2 = d_id // BEHAVIOR_DIM, d_id % BEHAVIOR_DIM\n",
    "    return torch.concat((d1.unsqueeze(0), d2.unsqueeze(0))).t().float() / BEHAVIOR_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_descriptors(n):\n",
    "    descriptors = torch.zeros((n, BEHAVIOR_DIM**2), dtype=torch.float32)\n",
    "    for i in range(n):\n",
    "        descriptors[i, torch.randint(0, BEHAVIOR_DIM**2, size=(1,))] = 1.\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(action):\n",
    "    return torch.tanh(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env, model, condition_descriptor, n_steps: int):\n",
    "    \n",
    "    states = np.zeros((env.num_envs, n_steps, env.single_observation_space.shape[0]), dtype=np.float32)\n",
    "    actions = np.zeros((env.num_envs, n_steps, env.single_action_space.shape[0]), dtype=np.float32)\n",
    "    rewards = np.zeros((env.num_envs, n_steps), dtype=np.float32)\n",
    "    log_ps = np.zeros((env.num_envs, n_steps), dtype=np.float32)\n",
    "    state_values = np.zeros((env.num_envs, n_steps), dtype=np.float32)\n",
    "    dones = np.zeros((env.num_envs, n_steps), dtype=np.float32)\n",
    "    info = np.zeros((env.num_envs, n_steps, 2), dtype=np.float32)\n",
    "    \n",
    "    advantages = np.zeros((env.num_envs, n_steps), dtype=np.float32)\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        # print(state.shape, alpha.shape)\n",
    "        with torch.no_grad():\n",
    "            action, action_mean, log_p, state_value, entropy = model(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(post_process(action).cpu().tolist())\n",
    "        done = (terminated | truncated)\n",
    "        \n",
    "        states[:, s] = state.cpu()\n",
    "        actions[:, s] = action.cpu()\n",
    "        rewards[:, s] = reward\n",
    "        log_ps[:, s] = log_p.cpu().detach().numpy()\n",
    "        state_values[:, s] = state_value.cpu().detach().reshape(-1).numpy()\n",
    "        dones[:, s] = done\n",
    "        info[:, s] = [(int(5 in env_.data.contact.geom2), int(8 in env_.data.contact.geom2)) for env_ in env.envs]        \n",
    "\n",
    "        state = next_state\n",
    "        # total_reward += reward\n",
    "        # step_count += 1\n",
    "\n",
    "        if done.any():\n",
    "            # state, _ = env.reset(np.where(dones)[0])\n",
    "            state, _ = env.reset()\n",
    "    \n",
    "    \n",
    "    \n",
    "    condition_descriptor_coord = descriptors_vec2coord(condition_descriptor)\n",
    "    achieved_descriptors = get_descriptors_from_trajectories({'info': info, 'done': dones})\n",
    "    achieved_descriptors = torch.tensor(achieved_descriptors).to(device)\n",
    "    \n",
    "    \n",
    "    # Calculate the distance between the goal descriptor and the achieved descriptor:\n",
    "    # print(achieved_descriptors, condition_descriptor_coord)\n",
    "    # descriptors_similarity = ((condition_descriptor_coord - achieved_descriptors)**2).sum(axis=-1)\n",
    "    # descriptors_similarity = torch.exp(-descriptors_similarity/0.1)\n",
    "    \n",
    "    # descriptors_similarity = achieved_descriptors.mean(-1)\n",
    "    descriptors_similarity = achieved_descriptors[:, 1]\n",
    "    \n",
    "    similarity_reward = descriptors_similarity.unsqueeze(1).repeat(1, n_steps).cpu()\n",
    "    \n",
    "    \n",
    "    critic_x = torch.FloatTensor(next_state).to(device)\n",
    "    next_value = model.critic(critic_x).cpu()    \n",
    "    \n",
    "        \n",
    "    states = torch.tensor(states)\n",
    "    actions = torch.tensor(actions)\n",
    "    real_rewards = torch.tensor(rewards)\n",
    "    rewards = similarity_reward\n",
    "    # rewards = real_rewards\n",
    "    # rewards = (10+real_rewards) * similarity_reward\n",
    "    \n",
    "    log_ps = torch.tensor(log_ps)\n",
    "    state_values = torch.tensor(state_values)\n",
    "    dones = torch.tensor(dones)\n",
    "    next_state_values = torch.concatenate((state_values[:, 1:], next_value), dim=-1)\n",
    "    \n",
    "\n",
    "    advantages, returns = [], []\n",
    "    for i in range(env.num_envs):\n",
    "        a, r = compute_gae(dones[i], rewards[i], state_values[i], next_state_values[i])\n",
    "        advantages.append(a)\n",
    "        returns.append(r)\n",
    "    advantages = torch.stack(advantages)\n",
    "    returns = torch.stack(returns)\n",
    "\n",
    "    # print(condition_descriptor_coord)\n",
    "    # print(achieved_descriptors)\n",
    "    # print(rewards)\n",
    "    # print(advantages)\n",
    "    # print(returns)\n",
    "    # return \n",
    "    \n",
    "    trajectories = {\n",
    "        \"descriptors\": condition_descriptor.unsqueeze(1).repeat(1, n_steps, 1).reshape(-1, BEHAVIOR_DIM**2),\n",
    "        \"states\" :  states.reshape(-1, env.single_observation_space.shape[0]).detach(),\n",
    "        \"actions\" : actions.reshape(-1, env.single_action_space.shape[0]).detach(),\n",
    "        \"rewards\" : rewards.reshape(-1).detach(),\n",
    "        \"dones\" : dones.reshape(-1).detach(),\n",
    "        \"log_ps\" : log_ps.reshape(-1).detach(),\n",
    "        \"state_values\": state_values.reshape(-1).detach(),\n",
    "        \"next_state_values\": next_state_values.reshape(-1).detach(),\n",
    "        \"returns\" : returns.reshape(-1).detach(),\n",
    "        \"advantages\" : advantages.reshape(-1).detach(),\n",
    "    }\n",
    "\n",
    "    return trajectories, {\n",
    "        'info':info, 'done':dones, \n",
    "        'reward': rewards, 'real_reward': real_rewards, \n",
    "        'similarity': similarity_reward\n",
    "    }\n",
    "\n",
    "\n",
    "def shufffle_trajectory(trajectories):\n",
    "    length = trajectories['states'].shape[0]\n",
    "    permutation = torch.randperm(length)\n",
    "\n",
    "    shuffled_trajectories = {key: tensor[permutation] for key, tensor in trajectories.items()}\n",
    "    return shuffled_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory, info = collect_trajectories(env, model, condition_descriptors, n_steps=max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_optimization(trajectories, model, optimizer, epochs, batch_size):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    traj_descriptors = trajectories[\"descriptors\"]\n",
    "    traj_states = trajectories[\"states\"]\n",
    "    traj_actions = trajectories[\"actions\"]\n",
    "    traj_log_ps = trajectories[\"log_ps\"]\n",
    "    traj_returns = trajectories[\"returns\"]  \n",
    "    traj_advantages = trajectories[\"advantages\"]\n",
    "\n",
    "\n",
    "    len_trajectory = traj_states.shape[0]\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for i in range(len_trajectory // batch_size):\n",
    "            alpha = traj_descriptors[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            state = traj_states[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            action = traj_actions[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            log_p = traj_log_ps[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            return_ = traj_returns[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            advantage = traj_advantages[batch_size*i:batch_size*(i+1)].to(device)\n",
    "                        \n",
    "            # print(alpha)\n",
    "            new_action, new_action_mean, new_log_p, new_state_value, entropy = model(state, action)\n",
    "            assert(new_action == action).all()\n",
    "            \n",
    "            \n",
    "            advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "\n",
    "            new_log_p, log_p, advantage = new_log_p.reshape(-1), log_p.reshape(-1), advantage.reshape(-1)\n",
    "            \n",
    "            ratio = torch.exp(new_log_p - log_p.detach())\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-0.2, 1+0.2) * advantage\n",
    "            policy_loss = - torch.min(surr1, surr2).mean()\n",
    "            \n",
    "            # print(policy_loss)\n",
    "            \n",
    "            \n",
    "            return_, new_state_value = return_.reshape(-1), new_state_value.reshape(-1)\n",
    "            critic_loss = ((return_ - new_state_value)**2).mean()\n",
    "        \n",
    "\n",
    "            loss = policy_loss - 2e-7*entropy.mean() + 0.5*critic_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_factor = torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "# ppo_optimization(trajectories, model, optimizer, epochs=1, batch_size=5)\n",
    "# ppo_optimization(shuffled_trajectory, model, alpha, optimizer, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, model, descriptor):\n",
    "    model.eval()\n",
    "\n",
    "    state, _ = env.reset()\n",
    "        \n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "\n",
    "    trajectory = []\n",
    "    info = []\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        trajectory.append(state)\n",
    "        state = torch.FloatTensor(state).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            action, mean_action, log_p, state_value, entropy = model(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(post_process(action)[0].cpu().tolist())\n",
    "\n",
    "        info.append((\n",
    "            int(5 in env.data.contact.geom2), int(8 in env.data.contact.geom2)\n",
    "        ))\n",
    "        \n",
    "        done = terminated or truncated\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "        \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    return total_reward, trajectory, info\n",
    "\n",
    "\n",
    "def get_reward_from_trajectory(info):\n",
    "    reward_list = []\n",
    "    real_reward_list = []\n",
    "    sim_list = []\n",
    "    acc_reward = 0\n",
    "    acc_real_reward = 0\n",
    "    acc_similarity = 0\n",
    "    for n in range(len(info['reward'])):\n",
    "        for i in range(len(info['reward'][n])):\n",
    "            if info['done'][n][i] == True:\n",
    "                reward_list.append(acc_reward)\n",
    "                real_reward_list.append(acc_real_reward)\n",
    "                sim_list.append(info['similarity'][n][-1])\n",
    "                acc_reward = 0\n",
    "                acc_real_reward = 0\n",
    "                acc_similarity = 0\n",
    "            \n",
    "            acc_reward += info['reward'][n][i]\n",
    "            acc_real_reward += info['real_reward'][n][i]\n",
    "            acc_similarity += info['similarity'][n][i]\n",
    "\n",
    "    return np.mean(reward_list), np.mean(real_reward_list), np.mean(sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.vector.make('HalfCheetah-v4', render_mode = \"rgb_array\", num_envs=8)\n",
    "\n",
    "max_episode_steps = 1000\n",
    "num_envs = 8\n",
    "env_fns = [lambda: gym.make('HalfCheetah-v4', render_mode=\"rgb_array\", max_episode_steps=max_episode_steps) for _ in range(num_envs)]\n",
    "env = gym.vector.SyncVectorEnv(env_fns)\n",
    "\n",
    "state_dim = env.observation_space.shape[-1]\n",
    "action_dim = env.action_space.shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/home/nazim/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.071, 0.108), (0.126, 0.308), (0.141, 0.288), (0.004, 0.019), (0.126, 0.324), (0.131, 0.31), (0.019, 0.045), (0.143, 0.293)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 211.84:   0%|          | 1/2000 [00:02<1:09:16,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.128, 0.271), (0.024, 0.045), (0.153, 0.296), (0.069, 0.077), (0.137, 0.2), (0.011, 0.038), (0.147, 0.321), (0.161, 0.294)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 192.71:   0%|          | 2/2000 [00:03<58:06,  1.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.102, 0.237), (0.163, 0.296), (0.069, 0.247), (0.123, 0.268), (0.108, 0.353), (0.164, 0.286), (0.117, 0.23), (0.161, 0.28)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 239.59:   0%|          | 4/2000 [00:06<52:03,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.136, 0.35), (0.113, 0.359), (0.035, 0.168), (0.172, 0.273), (0.045, 0.085), (0.115, 0.342), (0.01, 0.039), (0.151, 0.301)]\n",
      "[(0.022, 0.034), (0.032, 0.108), (0.047, 0.081), (0.126, 0.318), (0.017, 0.029), (0.183, 0.292), (0.132, 0.366), (0.143, 0.199)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 178.35:   0%|          | 5/2000 [00:08<50:46,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.046, 0.095), (0.052, 0.065), (0.035, 0.115), (0.013, 0.024), (0.077, 0.136), (0.164, 0.29), (0.028, 0.046), (0.133, 0.334)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 138.08:   0%|          | 6/2000 [00:09<50:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.017, 0.015), (0.101, 0.28), (0.025, 0.087), (0.113, 0.27), (0.17, 0.296), (0.17, 0.275), (0.109, 0.187), (0.01, 0.022)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 179.00:   0%|          | 7/2000 [00:10<49:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.065, 0.114), (0.154, 0.234), (0.006, 0.012), (0.136, 0.257), (0.005, 0.014), (0.155, 0.273), (0.016, 0.044), (0.002, 0.021)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reward: 121.12:   0%|          | 8/2000 [00:13<54:04,  1.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# condition_descriptors = random_descriptors(env.num_envs).to(device)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     condition_descriptors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(descriptors_to_vectors([(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mrepeat(env\u001b[38;5;241m.\u001b[39mnum_envs, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 27\u001b[0m     trajectory, info \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_descriptors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_episode_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     descriptors \u001b[38;5;241m=\u001b[39m get_descriptors_from_trajectories(info)\n\u001b[1;32m     30\u001b[0m     all_condition_descriptors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m condition_descriptors\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36mcollect_trajectories\u001b[0;34m(env, model, condition_descriptor, n_steps)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m     action, action_mean, log_p, state_value, entropy \u001b[38;5;241m=\u001b[39m model(state)\n\u001b[0;32m---> 24\u001b[0m next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m done \u001b[38;5;241m=\u001b[39m (terminated \u001b[38;5;241m|\u001b[39m truncated)\n\u001b[1;32m     27\u001b[0m states[:, s] \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/vector/vector_env.py:137\u001b[0m, in \u001b[0;36mVectorEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take an action for each parallel environment.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Batch of (observations, rewards, terminated, truncated, infos) or (observations, rewards, dones, infos)\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/vector/sync_vector_env.py:150\u001b[0m, in \u001b[0;36mSyncVectorEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m observations, infos \u001b[38;5;241m=\u001b[39m [], {}\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (env, action) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actions)):\n\u001b[1;32m    144\u001b[0m     (\n\u001b[1;32m    145\u001b[0m         observation,\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rewards[i],\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terminateds[i],\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncateds[i],\n\u001b[1;32m    149\u001b[0m         info,\n\u001b[0;32m--> 150\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terminateds[i] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncateds[i]:\n\u001b[1;32m    153\u001b[0m         old_observation, old_info \u001b[38;5;241m=\u001b[39m observation, info\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/envs/mujoco/half_cheetah_v4.py:198\u001b[0m, in \u001b[0;36mHalfCheetahEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    194\u001b[0m ctrl_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_cost(action)\n\u001b[1;32m    196\u001b[0m forward_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reward_weight \u001b[38;5;241m*\u001b[39m x_velocity\n\u001b[0;32m--> 198\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m reward \u001b[38;5;241m=\u001b[39m forward_reward \u001b[38;5;241m-\u001b[39m ctrl_cost\n\u001b[1;32m    200\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/envs/mujoco/half_cheetah_v4.py:213\u001b[0m, in \u001b[0;36mHalfCheetahEnv._get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m     position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqpos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     velocity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqvel\u001b[38;5;241m.\u001b[39mflat\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclude_current_positions_from_observation:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConditionedActorCriticContinuous(\n",
    "    BEHAVIOR_DIM**2,\n",
    "    state_dim,\n",
    "    action_dim,\n",
    "    actor_hidden_layers=[256, 256],\n",
    "    critic_hidden_layers=[256, 256],\n",
    "    action_std=0.5\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "rewards, real_rewards, similarities = [], [], []\n",
    "all_descriptors = []\n",
    "all_condition_descriptors = []\n",
    "\n",
    "H_d_a_list = []\n",
    "H_d_list = []\n",
    "cross_entropies = []\n",
    "diversity_lossses = []\n",
    "\n",
    "tqdm_epochs = tqdm(range(1, 2000+1))\n",
    "for epochs in tqdm_epochs:\n",
    "    \n",
    "    for _ in range(1):\n",
    "        # condition_descriptors = random_descriptors(env.num_envs).to(device)\n",
    "        condition_descriptors = torch.tensor(descriptors_to_vectors([(4,4)]), dtype=torch.float32).repeat(env.num_envs, 1).to(device)\n",
    "        trajectory, info = collect_trajectories(env, model, condition_descriptors, n_steps=max_episode_steps)\n",
    "        descriptors = get_descriptors_from_trajectories(info)\n",
    "        \n",
    "        all_condition_descriptors += condition_descriptors.tolist()\n",
    "        all_descriptors += descriptors\n",
    "        print(descriptors)\n",
    "\n",
    "    shuffled_trajectory = shufffle_trajectory(trajectory)\n",
    "    diversity_loss = ppo_optimization(shuffled_trajectory, model, optimizer, epochs=4, batch_size=512)\n",
    "    diversity_lossses.append(diversity_loss)\n",
    "    \n",
    "    final_reward, final_real_reward, final_similarity = get_reward_from_trajectory(info)\n",
    "    rewards.append(max(final_reward, -3000))\n",
    "    real_rewards.append(max(final_real_reward, -3000))\n",
    "    similarities.append(final_similarity)\n",
    "    \n",
    "    tqdm_epochs.set_description(f'Reward: {final_reward:.2f}')\n",
    "    \n",
    "    \n",
    "    if epochs % 10 == 0:\n",
    "        clear_output(True)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        axes[0].plot(rewards)\n",
    "        axes[0].set_title('Rewards')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Reward')\n",
    "        \n",
    "        axes[1].plot(real_rewards)\n",
    "        axes[1].set_title('Real Rewards')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Real Reward')\n",
    "        \n",
    "        axes[2].plot(similarities)\n",
    "        axes[2].set_title('Similarities')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Similarity')\n",
    "\n",
    "        # Display the plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1689,  0.1139,  0.2189, -0.2254, -0.2242,  0.1445], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.action_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   15.,   224.,  1702.,  6327., 11762., 14949., 10110.,  2552.,\n",
       "          327.,    32.]),\n",
       " array([-5.61361074, -4.49538326, -3.37715578, -2.25892806, -1.14070058,\n",
       "        -0.0224731 ,  1.09575438,  2.21398187,  3.33220959,  4.45043707,\n",
       "         5.56866455]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trajectory['actions'].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0702,  0.0623,  0.0305,  0.0386,  0.0350,  0.0269, -0.0184, -0.0036,\n",
       "         0.0552,  0.0692,  0.0946,  0.0280, -0.0460, -0.1589, -0.0833, -0.0471,\n",
       "        -0.0561])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory['states'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.606151, -1141.6158, 3.8897888e-05)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reward_from_trajectory(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0052, 0.0052, 0.0052,  ..., 0.0052, 0.0052, 0.0052],\n",
       "        [0.0095, 0.0095, 0.0095,  ..., 0.0095, 0.0095, 0.0095],\n",
       "        [0.0073, 0.0073, 0.0073,  ..., 0.0073, 0.0073, 0.0073],\n",
       "        ...,\n",
       "        [0.0058, 0.0058, 0.0058,  ..., 0.0058, 0.0058, 0.0058],\n",
       "        [0.0052, 0.0052, 0.0052,  ..., 0.0052, 0.0052, 0.0052],\n",
       "        [0.0093, 0.0093, 0.0093,  ..., 0.0093, 0.0093, 0.0093]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory['rewards'].reshape(8, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0052, 0.0052, 0.0052,  ..., 0.0052, 0.0052, 0.0052],\n",
       "        [0.0095, 0.0095, 0.0095,  ..., 0.0095, 0.0095, 0.0095],\n",
       "        [0.0073, 0.0073, 0.0073,  ..., 0.0073, 0.0073, 0.0073],\n",
       "        ...,\n",
       "        [0.0058, 0.0058, 0.0058,  ..., 0.0058, 0.0058, 0.0058],\n",
       "        [0.0052, 0.0052, 0.0052,  ..., 0.0052, 0.0052, 0.0052],\n",
       "        [0.0093, 0.0093, 0.0093,  ..., 0.0093, 0.0093, 0.0093]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/cond(4,4).pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ActorCriticContinuous(\n",
    "#     1,\n",
    "#     state_dim,\n",
    "#     action_dim,\n",
    "#     same_init=True,\n",
    "#     actor_hidden_layers=[256, 256],\n",
    "#     critic_hidden_layers=[256, 256],\n",
    "#     action_std=0.5\n",
    "# ).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('models/halfcheetah/n_anchors=1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nazim/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "single_env = gym.make('HalfCheetah-v4', render_mode=\"rgb_array\", max_episode_steps=max_episode_steps)\n",
    "\n",
    "descriptors = []\n",
    "desc_rewards = []\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    reward, states, info = evaluate(single_env, model, random_descriptors(1).to(device))\n",
    "    descriptors.append(get_descriptor(info))\n",
    "    rewards.append(reward)\n",
    "    \n",
    "descriptors_array = np.array(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1, x2 = 0, 1\n",
    "\n",
    "x1_min = 0\n",
    "x1_max = 1\n",
    "x2_min = 0\n",
    "x2_max = 1\n",
    "\n",
    "N = 30\n",
    "\n",
    "x1_bins = np.linspace(x1_min, x1_max, N)\n",
    "x2_bins = np.linspace(x2_min, x2_max, N)\n",
    "\n",
    "map_grid = np.full((N, N), np.nan)\n",
    "\n",
    "\n",
    "def get_bin(value, bins):\n",
    "    return np.digitize(value, bins) - 1\n",
    "\n",
    "\n",
    "for descriptor, reward in zip(descriptors, rewards):\n",
    "    feature1, feature2 = descriptor[x1], descriptor[x2]\n",
    "    f1_bin = get_bin(feature1, x1_bins)\n",
    "    f2_bin = get_bin(feature2, x2_bins)\n",
    "    \n",
    "    if np.isnan(map_grid[f1_bin, f2_bin]):\n",
    "        map_grid[f1_bin][f2_bin] = reward\n",
    "    else:\n",
    "        map_grid[f1_bin][f2_bin] = max(map_grid[f1_bin][f2_bin], reward) \n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "\n",
    "cax = axs.matshow(map_grid, cmap=\"viridis\", vmin=-1000, vmax=300)\n",
    "axs.set_title('DDPG\\n(Full oobservation)', loc='center')\n",
    "\n",
    "axs.set_xlabel('bfoot touch ground')\n",
    "axs.set_ylabel('ffoot touch ground')\n",
    "axs.set_xticks(np.linspace(0, N-1, num=11))\n",
    "axs.set_xticklabels(np.round(np.linspace(0, 1, num=11), 2))\n",
    "axs.set_yticks(np.linspace(0, N-1, num=11))\n",
    "axs.set_yticklabels(np.round(np.linspace(0, 1, num=11), 2))\n",
    "    \n",
    "fig.colorbar(cax, ax=axs, orientation='vertical', label='Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ActorCriticContinuous' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mActorCriticContinuous\u001b[49m(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m     state_dim,\n\u001b[1;32m      4\u001b[0m     action_dim,\n\u001b[1;32m      5\u001b[0m     same_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     actor_hidden_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[1;32m      7\u001b[0m     critic_hidden_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[1;32m      8\u001b[0m     action_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      9\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/halfcheetah/n_anchors=1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ActorCriticContinuous' is not defined"
     ]
    }
   ],
   "source": [
    "model = ActorCriticContinuous(\n",
    "    1,\n",
    "    state_dim,\n",
    "    action_dim,\n",
    "    same_init=False,\n",
    "    actor_hidden_layers=[256, 256],\n",
    "    critic_hidden_layers=[256, 256],\n",
    "    action_std=0.5\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('models/halfcheetah/n_anchors=1.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_env = gym.make('HalfCheetah-v4', render_mode=\"rgb_array\", max_episode_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Action dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     action, _, log_p, state_value, entropy \u001b[38;5;241m=\u001b[39m model(state)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# action = torch.normal(0, 1, size=(action.shape))\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43mone_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add data to memory\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# memory.add(state, action, reward, action_logprob, done)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:214\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    216\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    217\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/envs/mujoco/half_cheetah_v4.py:190\u001b[0m, in \u001b[0;36mHalfCheetahEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    189\u001b[0m     x_position_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_skip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     x_position_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    192\u001b[0m     x_velocity \u001b[38;5;241m=\u001b[39m (x_position_after \u001b[38;5;241m-\u001b[39m x_position_before) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/envs/mujoco/mujoco_env.py:156\u001b[0m, in \u001b[0;36mBaseMujocoEnv.do_simulation\u001b[0;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Check control input is contained in the action space\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ctrl)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction dimension mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_mujoco_simulation(ctrl, n_frames)\n",
      "\u001b[0;31mValueError\u001b[0m: Action dimension mismatch"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "# alpha = torch.tensor([0.5.]).to(device)\n",
    "\n",
    "state, _ = one_env.reset()\n",
    "total_reward = 0\n",
    "tqdm_range = tqdm(range(max_timesteps))\n",
    "for t in tqdm_range:\n",
    "    state = torch.FloatTensor(state).to(device)\n",
    "    with torch.no_grad():\n",
    "        action, _, log_p, state_value, entropy = model(state)\n",
    "    # action = torch.normal(0, 1, size=(action.shape))\n",
    "    next_state, reward, terminated, truncated, _ = one_env.step(post_process(action)[0].cpu().tolist())\n",
    "    done = terminated or truncated\n",
    "    \n",
    "    # Add data to memory\n",
    "    # memory.add(state, action, reward, action_logprob, done)\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    \n",
    "    clear_output(True)\n",
    "    frame = one_env.render()\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    \n",
    "    # print(env.get_body_com('ffoot'))\n",
    "    # print(env.data.body('bfoot').cfrc_int, env.data.body('ffoot').cfrc_int)\n",
    "    \n",
    "    \n",
    "    # print(env.data.body('ffoot').xipos)\n",
    "    # print(env.data.body('bfoot').cfrc_ext.any(), env.data.body('ffoot').cfrc_ext.any())\n",
    "    # print(env.data.contact)\n",
    "    print(5 in one_env.data.contact.geom2, 8 in one_env.data.contact.geom2)\n",
    "    \n",
    "    # if env.data.contact.H.shape[0] != 0:\n",
    "        # break\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "    # sleep(1)\n",
    "    \n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8], dtype=int32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.contact.geom2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PyCapsule.body of <mujoco._structs.MjData object at 0x754a173cd070>>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  22.1293691 ,   0.        , -52.90674133,\n",
       "         0.        , -13.8416032 ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.body('ffoot').cfrc_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , -65.58391056,   0.        , 124.25011867,\n",
       "         0.        , -41.76418074])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.body('bfoot').cfrc_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MjDataBodyViews\n",
       "  cacc: array([   0.        , -731.05017666,    0.        ,  -51.67292521,\n",
       "          0.        ,  575.00922327])\n",
       "  cfrc_ext: array([0., 0., 0., 0., 0., 0.])\n",
       "  cfrc_int: array([  0.        , -65.58391056,   0.        , 124.25011867,\n",
       "         0.        , -41.76418074])\n",
       "  cinert: array([ 0.05770359,  0.76445357,  0.70785189,  0.        , -0.19661607,\n",
       "        0.        , -0.87857201,  0.        , -0.24193659,  1.09539749])\n",
       "  crb: array([ 0.05770359,  0.76445357,  0.70785189,  0.        , -0.19661607,\n",
       "        0.        , -0.87857201,  0.        , -0.24193659,  1.09539749])\n",
       "  cvel: array([ 0.        ,  7.11009233,  0.        ,  5.33851089,  0.        ,\n",
       "       -5.19108022])\n",
       "  id: 4\n",
       "  name: 'bfoot'\n",
       "  subtree_angmom: array([0., 0., 0.])\n",
       "  subtree_com: array([2.04672575, 0.        , 0.42603072])\n",
       "  subtree_linvel: array([0., 0., 0.])\n",
       "  xfrc_applied: array([0., 0., 0., 0., 0., 0.])\n",
       "  ximat: array([ 0.77652312,  0.        ,  0.63008876,  0.        ,  1.        ,\n",
       "        0.        , -0.63008876,  0.        ,  0.77652312])\n",
       "  xipos: array([2.04672575, 0.        , 0.42603072])\n",
       "  xmat: array([ 0.5803259 ,  0.        ,  0.81438433,  0.        ,  1.        ,\n",
       "        0.        , -0.81438433,  0.        ,  0.5803259 ])\n",
       "  xpos: array([2.10831126, 0.        , 0.50675386])\n",
       "  xquat: array([0.8889111 , 0.        , 0.45807974, 0.        ])\n",
       ">"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.body('bfoot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03/11/2024-21:15:50'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%d/%m/%Y-%H:%M:%S\")\n",
    "formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
     ]
    }
   ],
   "source": [
    "datetime.now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
